# Checklist
OS checklist

# Activity A – Research & Prep Checklist
This is my checklist for Activity A in the T Level Digital Production, Design & Development exam.  
 ### Activity 1 - Research and Preparation 
- [ ] Appendices
- [ ] How digital solutions are used to meet the needs of different users within the given scenario sector, including:
- [ ] How Hardware and software are used in the scenario of industry
- [ ]  newly emerging technologies
- [ ]  how digital solutions could be used to meet different user needs
- [ ]  the industry-specific guidelines and regulations you will need to follow.

---
 
## 1. Business Context
- [ ] Explain what the business actually does  
- [ ] What problem they want fixing  
- [ ] Who the users/stakeholders are
- [ ] SWOT Analysis
- [ ] User Stories
- [ ] Empathy mapping
- [ ] Any limits (budget, time, tech issues, security stuff etc.)  
- [ ] Why the project matters to the business  
 
---
 
## 2. Requirements
- [ ] List all the **functional requirements** (what the system should do)  
- [ ] List the **non-functional requirements** (speed, reliability, usability, security)  
- [ ] Note any inputs/outputs  
- [ ] Add any assumptions or things that might be a problem  
- [ ] Link the requirements back to the business problem  
 
---
 
## 3. Decomposition
Break the problem into smaller chunks.
 
- [ ] Write a simple breakdown of the whole system  
- [ ] List the main components/modules  
- [ ] Explain how data moves around the system  
- [ ] Add diagrams if needed:  
  - [ ] Flowchart  
  - [ ] System/architecture diagram  
  - [ ] Class/entity structure  
- [ ] Explain how each bit helps solve the problem  
 
---
 
## 4. KPIs & User Acceptance
- [ ] Write down the KPIs (basically how we know it works)  
- [ ] Add performance goals, uptime, accuracy, etc.  
- [ ] Create User Acceptance Criteria (Given / When / Then)  
- [ ] Make sure each requirement has something that can be tested  
- [ ] Link UAC back to the requirements  
 
---
 
## 5. Proposal
- [ ] Explain the solution you’re going to make  
- [ ] List the features and the tech you’ll use  
- [ ] Mention tools/frameworks (like Python, JS, databases, etc.)  
- [ ] Add rough project stages or milestones  
- [ ] Mention any risks + how you’d deal with them  
- [ ] Say what the final outcome should achieve  
 
---
 
## 6. Justification
- [ ] Explain why your solution is the best idea  
- [ ] Briefly mention other options and why you didn’t pick them  
- [ ] Justify the tech choices  
- [ ] Justify the design/architecture  
- [ ] Justify the tools, libraries, methods, etc.  
- [ ] Link everything back to the business needs + KPIs  
 
---
 
## 7. Appendices
- [ ] Add diagrams  
- [ ] Add bigger bits of code  
- [ ] Add screenshots/mockups  
- [ ] Add any extra research  
- [ ] Make sure everything is labelled so the examiner knows what it is  
 
---
 
## Final Checks
- [ ] Everything in the right order  
- [ ] Makes sense + reads clearly  
- [ ] No typos  
- [ ] Diagrams are actually readable  
- [ ] All points in Activity A have been covered  
 
 
 ## Algorithm
 Use pseudocode/flowchart to explain functional parts
 Justify each algorithm.
 Show example of data (data table)

---
 
### End of Checklist
## Activity B Checklist
-Create UI, wireframes, canva,figma, draw.io
-Show user journeys, use a table
-Justify colours used
-W3C/WCAG guideilines (POUR)
-Front-end and back-end requirements
### Visual Interface Design
- [ ] **Wireframes Created**
- - [ ] Whitespace
- - [ ] Hierarchy 
- - [ ] Make look good
### Data Requirements
 - [ ] ERD Completed
 - [ ] Use Case Diagram
 - [ ] Data Dictionary
 - [ ] Class Diagram
 - [ ] - [ ] **Data Flow Diagram**
- [ ] **Accessibility Features Included**
 - [ ] Annotations
 - [ ] User Journey
 - [ ] Front end requirements
 - [ ] Back end requirements

- [ ] **Annotations**

- [ ] **User Journey**

- [ ] **Front end requirements**

- [ ] **Back end requirements**




### Algorithm Designs
- [ ] **Flow charting**
- [ ] **Navigation Maps**

### Test Stratagey
- [ ] **Functionality Testing**  
  Verifies that each feature works according to requirements.

- [ ] **Usability Testing**  
  How easy a design is to use with a group of users.

- [ ] **Interface Testing**  
  How different components communicate with each other smoothly and accurately.

- [ ] **Database Testing**  
  Evaluate the accuracy, reliability, and performance of a database system.

- [ ] **Compatibility Testing**  
  Ensure the application can work on different hardware and environments.

- [ ] **Performance Testing**  
  Determine a system’s speed, stability, and scalability under a specific workload.

- [ ] **Security Testing**  
  Evaluate a system to find vulnerabilities and weaknesses that could be exploited.

- [ ] **Crowd Testing**  
  Quality assurance performed by a group of external testers.

- [ ] **Accessibility Testing**  
  Check if a website is usable by everyone, including people with disabilities.

- [ ] **Acceptance Testing**  
  Verify that the product meets the requirements and user needs.

- [ ] **Alpha Testing**  
  Internal testers identify any issues or improvements needed.

- [ ] **Beta Testing**  
  External users give feedback on usability and performance.

- [ ] **Black Box Testing**  
  Test functionality without looking into internal structures or inner workings.

- [ ] **White Box Testing / Structural Testing**  
  Test the inner workings and logic by analysing the source code.

### Task 2
- [ ] 2 Programming languages, python, html,sql,javascript ,css
- [ ] Front end, back end, good ui, code organisation, legal guidelines
- [ ] Changelog/version history
- [ ] Asset log
- [ ] Test log, suitable test data


### OS Task 3A Action Steps 
- [ ] **Validation:** I have tested my survey links to ensure they are public/accessible. 

- [ ] **Bias Audit:** I have checked my questions to ensure they aren't "leading" the user. 

- [ ] **Synthesis:** I have written a "Results Summary" that links Technical and Non-Technical findings. 

- [ ] **Traceability:** I have mapped every user "pain point" to a specific GitHub Issue or Future Improvement item.
- [ ] Explain why feedback is being collected, link to improving prototype
- [ ] Clear explanation of what needs to be found out
- [ ] Target users
- [ ] Justification for each group
- [ ] **Feedback Methods**:
- [ ] Surveys,interviews, justification for each method, how each method links to the aims
- [ ] **Practical session plan**
- [ ] Where feedback takes place
- [ ] what test environment will be used
- [ ] Tasks users will complete
- [ ] How the prototype will be shown
- [ ] **Data Recording**
- [ ] How survey data will be stored
- [ ] How interview notes will be captured
- [ ] **Data Analysis**
- [ ] Calculate Averages
- [ ] Identify lowest scoring
- [ ] Group interview comments

## Section 2 Task 3A
- [ ] **Technical Survey questions**
- [ ] 5 quantitive questions
- [ ] 3-5 qualitatives
- [ ] Performance,code quality, logic
- [ ] No repeated questions
- [ ] **Non Technical Survey**
- [ ] at least 5 quantitive
- [ ] 3-5 qualitive
- [ ] Usability,navigation,clarity,accessibility, design

- [ ] **Interview**
- [ ] **Non Technical**:
- [ ] 5 open questions
- [ ] Probes
- [ ] Not repetitive
- [ ] **Technical**:
- [ ] 5 open questions
- [ ] efficiency,maintainability,logic etc
- [ ] prototype specific
- [ ] **Triangulation**
- [ ] One low score, one theme, one quote
- [ ] Explain why they connect
- [ ] **Analysis**
- [ ] Averages
- [ ] Comparisons
- [ ] Themes

